{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ibc_roberta.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1uop5XwsiWPqVd4M2wbx9IXzzCJx2zxcD",
      "authorship_tag": "ABX9TyM1GhaD+wvJBjm7UAPyWWem",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenghub/test/blob/master/ibc_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Yx-8GQ0b5y"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOrJPKGlzzjG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import activations, optimizers, losses\n",
        "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPzMevqS0Mzs"
      },
      "source": [
        "df_binary = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/ibc_lib_con.xlsx\")\n",
        "df_binary = df_binary[df_binary['class'].notna()]\n",
        "df_binary[\"label\"] = np.where(df_binary[\"class\"]==0, \"liberal\", \"conservative\")\n",
        "\n",
        "print(\"Liberal (0) and Conservative (1) sentence counts:\")\n",
        "df_binary[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNDudCsc01XW"
      },
      "source": [
        "features = df_binary[[\"sentence\"]]\n",
        "labels = df_binary[\"class\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oURaMAxG09ru"
      },
      "source": [
        "undersample = RandomUnderSampler(sampling_strategy=\"majority\")\n",
        "X_under, y_under = undersample.fit_resample(features, labels)\n",
        "\n",
        "# To check balance\n",
        "from collections import Counter\n",
        "print(Counter(y_under))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3gI9IsG0_gb"
      },
      "source": [
        "train_pct = 0.8\n",
        "# Split into train (80%) dev (10%) test (10%)\n",
        "# Splitting up the sentences and targets\n",
        "# Set seed guarantees sentences and targets shuffle in same order, split the data with the same class distribution\n",
        "train_sents, dev_test_sents = train_test_split(X_under, train_size=train_pct, random_state=42,\n",
        "                                          stratify=y_under, shuffle=True)\n",
        "\n",
        "train_labels, dev_test_labels = train_test_split(y_under, train_size=train_pct, random_state=42,\n",
        "                                            stratify=y_under, shuffle=True)\n",
        "\n",
        "dev_sents, test_sents = train_test_split(dev_test_sents, train_size=0.5,random_state=42,\n",
        "                                         stratify=dev_test_labels, shuffle=True)\n",
        "\n",
        "dev_labels, test_labels = train_test_split(dev_test_labels, train_size=0.5, random_state=42,\n",
        "                                           stratify=dev_test_labels, shuffle=True)\n",
        "X_train = train_sents\n",
        "y_train = train_labels\n",
        "\n",
        "X_dev = dev_sents\n",
        "y_dev = dev_labels\n",
        "\n",
        "X_test = test_sents\n",
        "y_test = test_labels\n",
        "#\n",
        "print(\"training shape X, y:\", X_train.shape, y_train.shape)\n",
        "print(\"dev shape X, y:\", X_dev.shape, y_dev.shape)\n",
        "print(\"test shape X, y:\", X_test.shape, y_dev.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYSj4UU91BoJ"
      },
      "source": [
        "y_train = y_train.tolist()\n",
        "y_dev = y_dev.tolist()\n",
        "y_test = y_test.tolist()\n",
        "\n",
        "train_labels = [int(i) for i in y_train]\n",
        "dev_labels = [int(i) for i in y_dev]\n",
        "test_labels = [int(i) for i in y_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A75ScgxD1Do0"
      },
      "source": [
        "X_tr = list(itertools.chain.from_iterable(X_train))\n",
        "X_d = list(itertools.chain.from_iterable(X_dev))\n",
        "X_te = list(itertools.chain.from_iterable(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAC3fuHZ1FaN"
      },
      "source": [
        "MODEL_NAME = 'roberta-base'\n",
        "\n",
        "review = X_tr[0]\n",
        "\n",
        "tkzr = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "inputs = tkzr(review, truncation=True, padding=True)\n",
        "\n",
        "print(f'review: \\'{review}\\'')\n",
        "print(f'input ids: {inputs[\"input_ids\"]}')\n",
        "print(f'attention mask: {inputs[\"attention_mask\"]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwRbCO1h1ILn"
      },
      "source": [
        "def construct_encodings(x, tkzr, trucation=True, padding=True):\n",
        "    return tkzr(x, truncation=trucation, padding=padding)\n",
        "\n",
        "train_encodings = construct_encodings(X_tr, tkzr)\n",
        "dev_encodings = construct_encodings(X_d, tkzr)\n",
        "test_encodings = construct_encodings(X_te, tkzr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2VrsOxh1d--"
      },
      "source": [
        "def construct_tfdataset(encodings, y=None):\n",
        "    if y:\n",
        "        return tf.data.Dataset.from_tensor_slices((dict(encodings),y))\n",
        "    else:\n",
        "        # this case is used when making predictions on unseen samples after training\n",
        "        return tf.data.Dataset.from_tensor_slices(dict(encodings))\n",
        "\n",
        "train_tfdataset = construct_tfdataset(train_encodings, train_labels)\n",
        "dev_tfdataset = construct_tfdataset(dev_encodings, dev_labels)\n",
        "test_tfdataset = construct_tfdataset(test_encodings, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNQCnDnt1g17"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "tfdataset_train = train_tfdataset.batch(BATCH_SIZE)\n",
        "tfdataset_dev = dev_tfdataset.batch(BATCH_SIZE)\n",
        "tfdataset_test = test_tfdataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEz7UTtD1k1i"
      },
      "source": [
        "\n",
        "N_EPOCHS = 5\n",
        "\n",
        "model = TFRobertaForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "optimizer = optimizers.Adam(learning_rate=5e-5)\n",
        "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "model.fit(tfdataset_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HItZ-DoS1oVr"
      },
      "source": [
        "benchmarks = model.evaluate(tfdataset_test, return_dict=True, batch_size=BATCH_SIZE)\n",
        "print(benchmarks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYP42Jbz1qWL"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LahNIQ_attnv"
      },
      "source": [
        "logits = model.predict(tfdataset_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PykaWYn4cevz"
      },
      "source": [
        "preds = np.argmax(logits[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytyj_oChcugi"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j5cujkYfwy2"
      },
      "source": [
        "true = np.asarray(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmXaKo8pgonM"
      },
      "source": [
        "confusion_matrix(true, preds, labels=[1,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL76Amf_g3dm"
      },
      "source": [
        "true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYomJfOn4eaz"
      },
      "source": [
        "np.where(preds!=true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdf47x8oCu8Y"
      },
      "source": [
        "np.argsort(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YsFVo26CuUH"
      },
      "source": [
        "test_index = 217\n",
        "\n",
        "print(X_test[test_index])\n",
        "print(true[test_index])\n",
        "print(preds[test_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjTKkfD4Ecao"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}